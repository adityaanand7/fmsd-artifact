
## <h1 align="center"> FMSD Artifact

1. Title of the paper: "Partial Program Analysis for Staged
Compilation Systems"

2. For downloading the artifact: git clone the repo.

## Overview: Artifact contents and badges clamied

* The artifact is contained in a fmsd directory. It contains the java class files which can be used to artifact results.

  
## Artifact Requirements

We have performed our experiments on an Intel Xeon E5-2630 2.4 GHz system with 32 cores and 64 GB of RAM, running Cent OS version 7.
So for running the benchmark it is required to have similar kind of configuration, however for running the sample program it should be fine on a machine with fewer cores and lesser RAM as well.

## Getting Started

###	 1. Starting with execution 

After cloning the repository, the source code can be found in the fmsd directory. The directory contains four folders 
> &nbsp;&nbsp; 1. benchmarks   &nbsp;&nbsp; 2. jdk1.8.0_301 &nbsp;&nbsp; 3. StagedAnalysis &nbsp;&nbsp; 4. WholeProgramAnalysis

and three files 
> 1. staged.sh &nbsp;&nbsp; 2. wholeprogram.sh 3. LICENSE &nbsp;&nbsp; 4. README.md.` 

#### Executing the Staged Analysis:

1. Staged analysis can be performed using the ***staged.sh*** script:
	  <code> bash ./staged.sh </code> 
	  
2. Provide paths for class_path and class_name in script : 

*	For example for running a sample program present in [benchmarks/tests/mytest](benchmarks/tests/mytest) directory.  
	* class\_path should be `class_path="${projectpath}/fmsd/benchmarks/tests/mytest/"`
	* and class\_name should be `class_name="Main"`
* Similarly for running a benchmark program, like Moldyn from JGF benchmark suit present in the benchmarks directory at [benchmarks/jgf/Moldyn/](benchmarks/jgf/Moldyn/) 
	* class\_path should be `class_path="${projectpath}/fmsd/benchmarks/jgf/Moldyn/"`
	* and class\_name should be `class_name="JGFMolDynBenchSizeA"`

Note that our artifact is independent of the programs and be used by just providing the class_path and class_name as mentioned above.
Staged Analysis is performed in 4 phases. The first two phases generate results for application methods and library methods, respectively. The third and the final phases generate the specialized code and the final analysis result, respectively.

##### PHASES 1 and 2 

The first two phases (1. Application Evaluation) and (2.LibraryEvaluation) comprise of three "Steps":

1. Generating the dependencies. For example, for moldyn, the file [StagedAnalysis/1.ApplicationEvaluation/0.Stava/scripts/CVOUT.txt](StagedAnalysis/1.ApplicationEvaluation/0.Stava/scripts/CVOUT.txt) consists of 473 dependencies (the entry 3 in Figure 11); note that in the paper, 474 was a minor typo `[Expected time: 20-30 seconds]`. Similarly, all the dependencies constituting entry 4 in Figure 11 are generated in [StagedAnalysis/2.LibraryEvaluation/0.Stava/res/](StagedAnalysis/2.LibraryEvaluation/0.Stava/res/) `[Expected time: 25-30 minutes]`.
        
2. Prepass division of dependencies. For example, for moldyn, the files in [StagedAnalysis/2.LibraryEvaluation/1.PrePass/evalout/](StagedAnalysis/2.LibraryEvaluation/1.PrePass/evalout/) constitute the result of the division prepass over the input dependencies (entry 7 in Figure 11) present in the "res" folder generated by Step 1 `[Expected time: 90-125 minutes]`.
        
3. Generating partial result for the dependencies from Step 2. For example, [StagedAnalysis/1.ApplicationEvaluation/2.Evaluator/PartialRes.txt](StagedAnalysis/1.ApplicationEvaluation/2.Evaluator/PartialRes.txt) contains the partial result generated for the application code of moldyn (entry 8 in Figure 11) `[Expected time: 80-85 seconds]`, and [StagedAnalysis/2.LibraryEvaluation/2.Evaluator/finalout/](StagedAnalysis/2.LibraryEvaluation/2.Evaluator/finalout/) consists of the partial results for the library dependencies of moldyn (entry 9 in Figure 11)`[Expected time: 90-95 minutes]`.

##### PHASES 3 and 4 

The third phase generates the specialized code as a result of specializing the evaluator with the partial results, and the fourth phase executes the specialized code by supplying the partially evaluated dynamic dependencies generated in Step 3 above.
    The third and the fourth phases are performed in two ways (entries 10 and 11 respectively in Figure 11):
        
- The "First Way" generates the specialized code constituting the partial-result evaluator for each program element in [StagedAnalysis/3.Specializer/1.MixAlgo-Normal/output/](StagedAnalysis/3.Specializer/1.MixAlgo-Normal/output/), and generates the final analysis result in [StagedAnalysis/4.PartialResultEvaluation/Evaluation/output/out.txt](StagedAnalysis/4.PartialResultEvaluation/Evaluation/output/out.txt) `[Expected time: 35-85 seconds]`.
- The "Second Way (Wrapper)" generates the partial-result evaluator in [StagedAnalysis/3.Specializer/2.MixAlgo-Wrapper/output/SpecializedCode.java](StagedAnalysis/3.Specializer/2.MixAlgo-Wrapper/output/SpecializedCode.java), and generates the same analysis result more efficiently in [StagedAnalysis/4.PartialResultEvaluation/Wrapper/output/out.txt](StagedAnalysis/4.PartialResultEvaluation/Wrapper/output/out.txt) `[Expected time: 2-6 seconds]`.

**IMPORTANT REMARK**: Based on the machine used and its workload (an isolated execution is preferred), the numbers obtained for various statistics may vary a bit (due to the common unpredictability associated with running java code), but in general, would follow the trends shown in the paper.

#### Inspecting the Outputs:

Observe that each step above also lists down the file in which the corresponding result is generated. Each of these files can be inspected either using an editor, or using the `cat` command (e.g. `cat StagedAnalysis/4.PartialResultEvaluation/Evaluation/output/out.txt` contains the final output after the staged analysis).
 
#### EXTENSIBILITY 

Our contributions to generate partial results and partial-result evaluators are independent of the benchmark, once the used CVGen<sub>ea</sub> generates the conditional-values for a given program. In order to extend the CVGen<sub>ea</sub> to work with newer benchmarks, we provide the steps below:     
    
1. Keep all the class files for the benchmark in a folder; e.g., we have created another folder for the raytracer benchmark of the JGF suite in [benchmarks/jgf/Raytracer](benchmarks/jgf/Raytracer).
    
2. Change the value of the variable "benchmark_path" in [StagedAnalysis/1.ApplicationEvaluation/0.Stava/scripts/jgfbenchmark.sh](StagedAnalysis/1.ApplicationEvaluation/0.Stava/scripts/jgfbenchmark.sh) to the path of the folder containing the benchmark class files (e.g., [/jgf/Raytracer](/jgf/Raytracer)" for raytracer).
    
3. Change the value of the variable "main_class" in [StagedAnalysis/1.ApplicationEvaluation/0.Stava/scripts/jgfbenchmark.sh](StagedAnalysis/1.ApplicationEvaluation/0.Stava/scripts/jgfbenchmark.sh) to the main (entry) class of the benchmark (e.g. "JGFRayTracerBenchSizeA" for raytracer).
    
Note that both steps 2 and 3 can be performed similarly for whole-program analysis by changing the two variables in the script [WholeProgramAnalysis/0.Stava/scripts/jgfbenchmark.sh](WholeProgramAnalysis/0.Stava/scripts/jgfbenchmark.sh).

